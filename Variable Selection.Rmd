---
title: "Variable Selection"
author: "Derrick Liu"
date: "4/24/2021"
output: html_document
---

```{r}
heart_dat <- read.csv("heart.csv")
head(heart_dat)

```

```{r}
heart_dat$sex <- as.factor(heart_dat$sex)
heart_dat$cp <- as.factor(heart_dat$cp)
heart_dat$fbs <- as.factor(heart_dat$fbs)
heart_dat$restecg <- as.factor(heart_dat$restecg)
heart_dat$exng <- as.factor(heart_dat$exng)
heart_dat$slp <- as.factor(heart_dat$slp)
heart_dat$caa <- as.factor(heart_dat$caa)
heart_dat$thall <- as.factor(heart_dat$thall)
#heart_dat$output <- as.factor(heart_dat$output)

heart_dat
```


# Lasso and Ridge

```{r}
# lasso - code adapted from Lab 5

library(glmnet)

train=sample(1:nrow(heart_dat), nrow(heart_dat)/2)
test = (-train)

grid=10^seq(10,-2,length=100)

x=model.matrix(output~.,heart_dat)[,-14]
y=heart_dat$output
y.test=y[test]

lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)
#lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid, family = binomial)
plot(lasso.mod)
```




```{r}
# continuing lasso - code adapted from Lab 5

set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
#cv.out=cv.glmnet(x[train,],y[train],alpha=1, family = binomial)
plot(cv.out)

bestlam=cv.out$lambda.min # tuning parameter
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])
mean((lasso.pred-y.test)^2) # MSE

out = glmnet(x,y,alpha=1,lambda=grid) # producing a model with 10 predictors
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:13,]
lasso.coef[lasso.coef!=0] 

bestlam
cv.out$lambda

```

This is saying that the model with the smallest lambda gives all the coefficients to be zero.
```{r}
min <- which.min(cv.out$lambda)
coef(lasso.mod)[,51]
```


```{r}
# ridge - code adapted from Lab 5

ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
#ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12, 
                 #family = binomial)
ridge.pred=predict(ridge.mod,newx=x[test,])
mean((ridge.pred-y.test)^2)

out2=glmnet(x,y,alpha=0)  # again, glmnet function is producing a model with not all zero values for the parameter estimates
# glmnet function fits a GLM with lasso or elastic net regularization
ridge.coef = predict(out2,type="coefficients",s=bestlam)[1:13,]
ridge.coef[ridge.coef!=0] 
```

We observe that the mean square error from lasso (0.1467082) is smaller than the
mean square error from ridge (0.2257933). 

```{r}
coef(ridge.mod)[,14]
```
These are all also essentially zero. This is really bizzare



# Fitting a logistic regression model

```{r}

# fitting a model with best subset selection

#library(caret)
library(MASS) # for the stepAIC function
library(dplyr) # for the pipeline operator

set.seed(1)

best_subset_logregmodel <- glm(output ~., data = heart_dat[train,], family = binomial) %>%
  stepAIC(trace = FALSE)

#train_samples <- heart_dat %>% 
  #createDataPartition(p = 0.9, list = FALSE)
#train.data <- heart_dat[train_samples]
#test.data <- heart_dat[-train_samples]
#full.model <- glm(output ~ ., data = train.data, family = binomial) %>%
  #stepAIC(trace = FALSE)

best_subset_logregmodel
summary(best_subset_logregmodel)
```

By best subset selection, the logistic regression model with the smallest AIC 
value is 
log(P(output = 1)) = 4.06126-0.04456*age-1.01364*sex+0.84954*cp+0.79620*restecg -1.60837*exng-0.52590*oldpeak+0.92052*slp-0.69045*caa-0.73848*thall

^has 9 total predictors (I am only counting 6 predictors)

```{r}
# fitting a model with forward stepwise selection

forward_logregmodel <- glm(output ~., data = heart_dat[train,], family = binomial) %>%
  stepAIC(direction = "forward", trace = FALSE)

forward_logregmodel
summary(forward_logregmodel)
```

By forward stepwise selection, the logistic regression model with the smallest
AIC value is 

log(P(output = 1)) = 2.5504570-0.0277105*age-1.0056065*sex+0.8132523*cp-0.0115987*trtbps -0.0007255*chol+0.0291891*fbs+0.8567083*restecg+0.0162629*thalachh-1.3413673*exng-0.4693130*oldpeak+0.7931857*slp -0.7187493*caa-0.7710355*thall

^has all 13 total predictors

```{r}
# fitting a model with backward stepwise selection

backward_logregmodel <- glm(output ~., data = heart_dat[train,], family = binomial) %>%
  stepAIC(direction = "backward", trace = FALSE)

backward_logregmodel
```

I get the same model from backward stepwise selection as I get from best subset
selection.

The model chosen by best subset selection/backward stepwise selection has an AIC
value (127.6) that is smaller than the AIC of the model chosen by forward 
stepwise selection (133.9). 

Using LDA for the best model
```{r}
dt = sort(sample(nrow(heart_dat), nrow(heart_dat)*.9))
train<-heart_dat[dt,]
test<-heart_dat[-dt,]

lda_best <- lda(output~ sex + cp + trtbps + fbs + exng + oldpeak + slp + caa + thall, 
                data = train)
lda_best_pred <- predict(lda_best, test)

table(lda_best_pred$class, test$output)
```

Using QDA for the best model
```{r}

qda_best <- qda(output~ sex + cp + trtbps + fbs + exng + oldpeak + slp + caa + thall, 
                data = train)
qda_best_pred <- predict(qda_best, test)

table(qda_best_pred$class, test$output)
```

```{r}
# Performing validation set approach

#training = sample(x = 1:nrow(heart_dat), size = nrow(heart_dat)/2)

training = sample(c(TRUE, FALSE), nrow(heart_dat), rep = TRUE)
testing = (!train)

training_dat <- heart_dat[training,]
testing_dat <- heart_dat[-training,]

anna.best2 <- regsubsets(output~., data = training_dat, nvmax = 13 )
test.matrix2 <- model.matrix(output~., data = testing_dat)

val.errors2=rep(NA,13)
for(i in c(1:13)){
coefi2=coef(anna.best2,id=i)
pred2=test.matrix2[,names(coefi2)]%*%coefi2
val.errors2[i]=mean((testing_dat$output-pred2)^2)
}
which.min(val.errors2)

```

```{r}
# finding best model from variable selection methods using 10-fold CV
# I am confused with the folds part of this code


k = 10
set.seed(1)
folds = sample(1:k, nrow(heart_dat), replace = TRUE)
cv.errors = matrix(NA, k, 13, dimnames = list(NULL, paste(1:13)))

for(j in 1:k){ 
  #best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13) 
  
  for(i in 1:13){
    pred=predict(best_subset_logregmodel,heart_dat[folds==j,], id = i) #what does id do?
    cv.errors[j,i]=mean((heart_dat$output[folds==j]-pred)^2)
  } 
}

mean.cv.errors = apply(cv.errors, 2, mean)
mean.cv.errors

# alternate method --> producing NAs

#library(boot)

#cv.error.10=rep(0,10) 
#for (i in 1:10){ 
 # cv.error.10[i]=cv.glm(heart_dat,best_subset_logregmodel,K=10)$delta[1] 
#} 
#cv.error.10
```

Anna-I am trying this out
```{r}
set.seed(1)
model_saver <- matrix(ncol = 10)
cv.errors2 = matrix(NA, k, 13)
intercept <- matrix(NA, k, 11)

for(j in 1:k){ 
  #best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13) 
   best_subset_logregmodel <- glm(output ~., data = heart_dat[folds != j,], family = binomial) %>%
  stepAIC(trace = F)
  model_saver[j] <- length(best_subset_logregmodel$coefficients)  #saves the number of non-zero coefficients
  intercept[j,] <- best_subset_logregmodel$coefficients[1:11]     #looks at model coefficients
  
    for(i in 1:13){
    pred=predict(best_subset_logregmodel,heart_dat[folds==j,], type = "response") #what does id do? id does nothing
    pred = ifelse(pred > 0.5, 1, 0)
    cv.errors2[j, i]=mean((heart_dat$output[folds==j] != pred))
    }
}

mean.cv.errors.anna = mean(cv.errors2)
#cv.errors2[,1]
intercept
#model_saver
```


Anna - this is telling me that the models with 10,11 - 14 predictors give basically the same test errors with logsitcs reg. My brain hurts
```{r}
cv.errors3 = matrix(NA, k, 13)
intercept2 <- matrix(NA, k, 14)
model_saver2 <- matrix(ncol = 14)

for(j in 1:k){ 
  #best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13) 
  forward_logregmodel <- glm(output ~., data = heart_dat[folds != j,], family = binomial) %>%
  stepAIC(direction = "forward", trace = FALSE)
  model_saver2[j] <- length(forward_logregmodel$coefficients)   #saves the number of non zero coefficients
  intercept2[j,] <- forward_logregmodel$coefficients[1:14] #looks at model coeffeicent
  
    for(i in 1:13){  
    pred=predict(forward_logregmodel,heart_dat[folds==j,], type = "response") #what does id do? id does nothing
    pred = ifelse(pred > 0.5, 1, 0)
    cv.errors3[j,i]=mean(heart_dat$output[folds==j] != pred)
    } 
}

mean.cv.errors.anna = mean(cv.errors3)
#cv.errors3[,1]
intercept2
#model_saver2
```




```{r}
# finding best model from variable selection methods using 5-fold CV

k2 = 5
set.seed(1)
folds = sample(1:k2, nrow(heart_dat), replace = TRUE)
cv.errors2 = matrix(NA, k2, 13, dimnames = list(NULL, paste(1:13)))

for(j in 1:k2){ 
  #best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13) 
  
  for(i in 1:13){
    pred=predict(best_subset_logregmodel,heart_dat[folds==j,],id=i)
    cv.errors2[j,i]=mean((heart_dat$output[folds==j]-pred)^2)
  } 
}

#mean.cv.errors2 = apply(cv.errors2, 2, mean)
#which.min(mean.cv.errors2)
cv.errors2
```


# Best subset selection

```{r}
library(leaps)

best_subset_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13)
best_subset_summ <- summary(best_subset_fit)
```

```{r}
which.min(best_subset_summ$bic)
which.min(best_subset_summ$cp)
```

```{r}
# Finding the number of predictors in the models selected by best subset selection
# that has the largest R^2

plot(summary(best_subset_fit)$adjr2, xlab = "Number of Variables", 
     ylab = "Adjusted RSq", type = "l")
which.max(summary(best_subset_fit)$adjr2)
points(10, summary(best_subset_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
```

# Forward stepwise selection

```{r}
forward_step_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13, 
                               method = "forward")

forward_step_summ <- summary(forward_step_fit)
```

```{r}
# Finding the number of predictors in the models selected by forward stepwise 
# selection that has the largest R^2

plot(summary(forward_step_fit)$adjr2, xlab = "Number of Variables", 
     ylab = "Adjusted RSq", type = "l")
which.max(summary(forward_step_fit)$adjr2)
points(10, summary(forward_step_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
```

```{r}
which.min(forward_step_summ$bic)
which.min(forward_step_summ$cp)
```


# Backward stepwise selection

```{r}
backward_step_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13, 
                               method = "backward")

back_step_summ <- summary(backward_step_fit)
```

```{r}
# Finding the number of predictors in the models selected by backward stepwise 
# selection that has the largest R^2

plot(summary(backward_step_fit)$adjr2, xlab = "Number of Variables", 
     ylab = "Adjusted RSq", type = "l")
which.max(summary(backward_step_fit)$adjr2)
points(10, summary(backward_step_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
```

The adjusted R^2 value is the largest for the models with 10 predictors 
selected by each best subset selection, forward stepwise selection, and backward
stepwise selection.

```{r}
which.min(back_step_summ$bic)
which.min(back_step_summ$cp)
```


# Selecting the Best Model via Cross Validation

```{r}
# 10-fold cross validation for best subset selection fit - code adapted from Lab 4

predict.regsubsets = function (object ,newdata ,id ,...){ 
  form=as.formula(object$call[[2]]) 
  mat=model.matrix(form,newdata) 
  coefi=coef(object ,id=id) 
  xvars=names(coefi) 
  mat[,xvars]%*%coefi 
}

```

Cross validation selects an 13-variable model for the best subset selection fit.

```{r}
plot(mean.cv.errors, type = "b")
```

```{r}
# 10-fold cross validation for forward stepwise selection fit - code adapted from Lab 4

set.seed(1)
folds2 = sample(1:k, nrow(heart_dat), replace = TRUE)
cv.errors2 = matrix(NA, k, 13, dimnames = list(NULL, paste(1:13)))

for(j in 1:k){ 
  #best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13) 
  
  for(i in 1:13){
    pred=predict(forward_step_fit,heart_dat[folds2==j,],id=i)
    cv.errors2[j,i]=mean((heart_dat$output[folds2==j]-pred)^2)
  } 
}

mean.cv.errors2 = apply(cv.errors2, 2, mean)
which.min(mean.cv.errors2)
```

Cross validation selects an 13-variable model for the best subset selection fit.

```{r}
plot(mean.cv.errors2, type = "b")
```

```{r}
# 10-fold cross validation for backward stepwise selection fit - code adapted from Lab 4

set.seed(1)
folds3 = sample(1:k, nrow(heart_dat), replace = TRUE)
cv.errors3 = matrix(NA, k, 13, dimnames = list(NULL, paste(1:13)))

for(j in 1:k){ 
  #best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13) 
  
  for(i in 1:13){
    pred=predict(backward_step_fit,heart_dat[folds3==j,],id=i)
    cv.errors3[j,i]=mean((heart_dat$output[folds3==j]-pred)^2)
  } 
}

mean.cv.errors3 = apply(cv.errors3, 2, mean)
which.min(mean.cv.errors3)
```

Cross validation selects an 13-variable model for the best subset selection fit.

```{r}
plot(mean.cv.errors3, type = "b")
```

Getting same results from best subset selection, forward stepwise selection, 
and backward stepwise selection --> not really sure why 

# logistic regression

```{r}
# model with all 13 predictors selected by cross validation

heart_logreg <- glm(output~.,
                    family = "binomial", data = heart_dat)
summary(heart_logreg)
```

```{r}
# model with just the statistically significant predictors from above

heart_logreg_red <- glm(output~sex+cp+thalachh+exng+oldpeak+caa+thall,
                    family = "binomial", data = heart_dat)
summary(heart_logreg_red)
```

All variables that were statistically significant in the model chosen from CV
are still statistically significant. 

# LDA

```{r}
# has to be chosen purposefully

train = (heart_dat$chol > 200)
```

```{r}
# LDA on the best model (with the lowest cross-validation error), which was the full model

library(MASS)

lda.fit = lda(output ~ ., 
              data = heart_dat, subset = train)

lda.fit
```

The coefficients of linear discriminants shows the linear combination of 
predictor variables that are used to form the LDA decision rule. 

# QDA
```{r}
# QDA on the best model, which has 11 predictors

library(MASS)

qda.fit = qda(output ~ sex+cp+trtbps+chol+restecg+thalachh+exng+oldpeak+slp+caa+thall, 
              data = heart_dat, subset = train)

qda.fit
```





Anna work, backwards model
```{r}

anna_model <- glm(output~., data = heart_dat, family = binomial)

anna_backwards <- step(anna_model)

summary(anna_backwards)

```


forwards model 
```{r}
anna_forwards <- step(anna_model, direction = "forward")

summary(anna_forwards)
```

```{r}
# hybrid of backward and forward, this is not best subset selection according to Elliot
# best subset selection may not be best --> have to consider 2^13 different models
# could use elastic net and lasso
# variable selection methods --> see how they work on the models that are chosen, not really trying to pick the "best model"

anna_best <- step(anna_model, direction = "both")
summary(anna_best)
```
My best subset model is the same as my backwards selected model.


```{r}
dt = sort(sample(nrow(heart_dat), nrow(heart_dat)*.9))
train<-heart_dat[dt,]
test<-heart_dat[-dt,]

anna.best <- regsubsets(output~., data = train, nvmax = 13 )
test.matrix <- model.matrix(output~., data = test)

val.errors=rep(NA,13)
for(i in c(1:13)){
coefi=coef(anna.best,id=i)
pred=test.matrix[,names(coefi)]%*%coefi
val.errors[i]=mean((test$output-pred)^2)
}
which.min(val.errors)
```
the best number of variables changes everytime.


Bestglm, used for logistic regression, regsubset supposedly only does linear models
```{r}
library(bestglm)
heart_dat2 <- heart_dat
names(heart_dat2)[14] <- "y"

best <- bestglm(heart_dat2, family = binomial, IC = "CV")
summary(best$BestModel)
```
Using bestglm model to see how we do with prediction
```{r}
anna_best_final <- glm(output~ sex + cp + thalachh + oldpeak + caa + thall, data = train, family = binomial)
anna_probs <- predict(anna_best_final, test, type = "response")
anna_pred <- rep(0, nrow(test))
anna_pred[anna_probs > 0.5] <- 1

table(anna_pred, test$output)
```
This gives a 71% accuracy


good old glm to stop making my head spin
```{r}
anna_backwards_final <-glm(formula = output ~ sex + cp + trtbps + restecg + thalachh + 
    exng + oldpeak + slp + caa + thall, family = binomial, data = train)
anna_probs <- predict(anna_backwards_final, test, type = "response")
anna_pred <- rep(0, nrow(test))
anna_pred[anna_probs > 0.5] <- 1

table(anna_pred, test$output)
```
This gives 83.8% accuracy

Using LDA for the best model
```{r}
lda_best <- lda(output~ sex + cp + thalachh + oldpeak + caa + thall, data = train)
lda_best_pred <- predict(lda_best, test)

table(lda_best_pred$class, test$output)
```
Does just slightly better than logistic regression


Using LDA for backwards model
```{r}
lda_backwards <- lda(formula = output ~ sex + cp + trtbps + restecg + thalachh + 
    exng + oldpeak + slp + caa + thall, data = train)
lda_backwards_preds <- predict(lda_backwards, test)

table(lda_backwards_preds$class, test$output)
```
does slightly worse than log reg

Lasso ***Still need to figure out****

```{r}
#library(glmnet)
x = heart_dat$output
y = model.matrix(output ~ ., data = heart_dat)[,-14]
grid = 10^seq(10,-2,length = 100)

lasso.mod = cv.glmnet(x,y,alpha = 1, lambda = grid, family = "binomial")


```

