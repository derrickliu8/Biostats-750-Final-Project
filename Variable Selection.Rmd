---
title: "Variable Selection"
author: "Derrick Liu"
date: "4/24/2021"
output: html_document
---

```{r}
heart_dat <- read.csv("heart.csv")
head(heart_dat)
```

# Lasso and Ridge

```{r}
# lasso - code adapted from Lab 5

library(glmnet)

train=sample(1:nrow(heart_dat), nrow(heart_dat)/2)
test = (-train)
y.test=y[test]

grid=10^seq(10,-2,length=100)

x=model.matrix(output~.,heart_dat)[,-14]
y=heart_dat$output

lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)
```

```{r}
# continuing lasso - code adapted from Lab 5

set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out)

bestlam=cv.out$lambda.min # tuning parameter
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])
mean((lasso.pred-y.test)^2) # MSE
```

```{r}
# ridge - code adapted from Lab 5

ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
ridge.pred=predict(ridge.mod,newx=x[test,])
mean((ridge.pred-y.test)^2)

```

We observe that the mean square error from lasso (0.156445) is smaller than the
mean square error from ridge (0.2350136). 

# Fitting a logistic regression model

```{r}

# fitting a model with best subset selection

library(caret)
library(MASS) # for the stepAIC function
library(dplyr) # for the pipeline operator

set.seed(1)

best_subset_logregmodel <- glm(output ~., data = heart_dat[train,], family = binomial) %>%
  stepAIC(trace = FALSE)

#train_samples <- heart_dat %>% 
  #createDataPartition(p = 0.9, list = FALSE)
#train.data <- heart_dat[train_samples]
#test.data <- heart_dat[-train_samples]
#full.model <- glm(output ~ ., data = train.data, family = binomial) %>%
  #stepAIC(trace = FALSE)

best_subset_logregmodel
```

By best subset selection, the logistic regression model with the smallest AIC 
value is 
log(P(output = 1)) = -1.03335-0.84768*sex+0.83206*cp+0.02041*thalachh-1.84894*exng-0.87327*oldpeak-0.79154*caa

```{r}
# fitting a model with forward stepwise selection

forward_logregmodel <- glm(output ~., data = heart_dat[train,], family = binomial) %>%
  stepAIC(direction = "forward", trace = FALSE)

forward_logregmodel
```

By forward stepwise selection, the logistic regression model with the smallest
AIC value is 

log(P(output = 1)) = 0.928318-0.014667*age-0.866589*sex+0.836280*cp+0.005887 *trtbps-0.003903*chol-0.587233*fbs+0.418808*restecg+0.016479*thalachh-1.757281*exng-0.830573*oldpeak+0.307920*slp -0.660102*caa-0.445072*thall

```{r}
# fitting a model with backward stepwise selection

backward_logregmodel <- glm(output ~., data = heart_dat[train,], family = binomial) %>%
  stepAIC(direction = "backward", trace = FALSE)

backward_logregmodel
```

I get the same model from backward stepwise selection as I get from best subset
selection.

The model chosen by best subset selection/backward stepwise selection has an AIC
value (116.4) that is smaller than the AIC of the model chosen by forward 
stepwise selection (126.8). 

# Best subset selection

```{r}

```


```{r}
library(leaps)

best_subset_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13)
best_subset_summ <- summary(best_subset_fit)
```

```{r}
which.min(best_subset_summ$bic)
which.min(best_subset_summ$cp)
```

```{r}
# Finding the number of predictors in the models selected by best subset selection
# that has the largest R^2

plot(summary(best_subset_fit)$adjr2, xlab = "Number of Variables", 
     ylab = "Adjusted RSq", type = "l")
which.max(summary(best_subset_fit)$adjr2)
points(10, summary(best_subset_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
```

# Forward stepwise selection

```{r}
forward_step_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13, 
                               method = "forward")

forward_step_summ <- summary(forward_step_fit)
```

```{r}
# Finding the number of predictors in the models selected by forward stepwise 
# selection that has the largest R^2

plot(summary(forward_step_fit)$adjr2, xlab = "Number of Variables", 
     ylab = "Adjusted RSq", type = "l")
which.max(summary(forward_step_fit)$adjr2)
points(10, summary(forward_step_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
```

```{r}
which.min(forward_step_summ$bic)
which.min(forward_step_summ$cp)
```


# Backward stepwise selection

```{r}
backward_step_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13, 
                               method = "backward")

back_step_summ <- summary(backward_step_fit)
```

```{r}
# Finding the number of predictors in the models selected by backward stepwise 
# selection that has the largest R^2

plot(summary(backward_step_fit)$adjr2, xlab = "Number of Variables", 
     ylab = "Adjusted RSq", type = "l")
which.max(summary(backward_step_fit)$adjr2)
points(10, summary(backward_step_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
```

The adjusted R^2 value is the largest for the models with 10 predictors 
selected by each best subset selection, forward stepwise selection, and backward
stepwise selection.

```{r}
which.min(back_step_summ$bic)
which.min(back_step_summ$cp)
```


# Selecting the Best Model via Cross Validation

```{r}
# 10-fold cross validation for best subset selection fit - code adapted from Lab 4

predict.regsubsets = function (object ,newdata ,id ,...){ 
  form=as.formula(object$call[[2]]) 
  mat=model.matrix(form,newdata) 
  coefi=coef(object ,id=id) 
  xvars=names(coefi) 
  mat[,xvars]%*%coefi 
}

k = 10
set.seed(1)
folds = sample(1:k, nrow(heart_dat), replace = TRUE)
cv.errors = matrix(NA, k, 13, dimnames = list(NULL, paste(1:13)))

for(j in 1:k){ 
  #best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13) 
  
  for(i in 1:13){
    pred=predict(best_subset_fit,heart_dat[folds==j,],id=i)
    cv.errors[j,i]=mean((heart_dat$output[folds==j]-pred)^2)
  } 
}

mean.cv.errors = apply(cv.errors, 2, mean)
which.min(mean.cv.errors)
```

Cross validation selects an 13-variable model for the best subset selection fit.

```{r}
plot(mean.cv.errors, type = "b")
```

```{r}
# 10-fold cross validation for forward stepwise selection fit - code adapted from Lab 4

set.seed(1)
folds2 = sample(1:k, nrow(heart_dat), replace = TRUE)
cv.errors2 = matrix(NA, k, 13, dimnames = list(NULL, paste(1:13)))

for(j in 1:k){ 
  #best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13) 
  
  for(i in 1:13){
    pred=predict(forward_step_fit,heart_dat[folds2==j,],id=i)
    cv.errors2[j,i]=mean((heart_dat$output[folds2==j]-pred)^2)
  } 
}

mean.cv.errors2 = apply(cv.errors2, 2, mean)
which.min(mean.cv.errors2)
```

Cross validation selects an 13-variable model for the best subset selection fit.

```{r}
plot(mean.cv.errors2, type = "b")
```

```{r}
# 10-fold cross validation for backward stepwise selection fit - code adapted from Lab 4

set.seed(1)
folds3 = sample(1:k, nrow(heart_dat), replace = TRUE)
cv.errors3 = matrix(NA, k, 13, dimnames = list(NULL, paste(1:13)))

for(j in 1:k){ 
  #best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13) 
  
  for(i in 1:13){
    pred=predict(backward_step_fit,heart_dat[folds3==j,],id=i)
    cv.errors3[j,i]=mean((heart_dat$output[folds3==j]-pred)^2)
  } 
}

mean.cv.errors3 = apply(cv.errors3, 2, mean)
which.min(mean.cv.errors3)
```

Cross validation selects an 13-variable model for the best subset selection fit.

```{r}
plot(mean.cv.errors3, type = "b")
```

Getting same results from best subset selection, forward stepwise selection, 
and backward stepwise selection --> not really sure why 

# logistic regression

```{r}
# model with all 13 predictors selected by cross validation

heart_logreg <- glm(output~.,
                    family = "binomial", data = heart_dat)
summary(heart_logreg)
```

```{r}
# model with just the statistically significant predictors from above

heart_logreg_red <- glm(output~sex+cp+thalachh+exng+oldpeak+caa+thall,
                    family = "binomial", data = heart_dat)
summary(heart_logreg_red)
```

All variables that were statistically significant in the model chosen from CV
are still statistically significant. 

# LDA

```{r}
# has to be chosen purposefully

train = (heart_dat$chol > 200)
```


```{r}
# LDA on the best model (with the lowest cross-validation error), which was the full model

library(MASS)

lda.fit = lda(output ~ ., 
              data = heart_dat, subset = train)

lda.fit
```

The coefficients of linear discriminants shows the linear combination of 
predictor variables that are used to form the LDA decision rule. 

# QDA
```{r}
# QDA on the best model, which has 11 predictors

library(MASS)

qda.fit = qda(output ~ sex+cp+trtbps+chol+restecg+thalachh+exng+oldpeak+slp+caa+thall, 
              data = heart_dat, subset = train)

qda.fit
```





Anna work, backwards model
```{r}

anna_model <- glm(output~., data = heart_dat, family = binomial)

anna_backwards <- step(anna_model)

summary(anna_backwards)

```


forwards model 
```{r}
anna_forwards <- step(anna_model, direction = "forward")

summary(anna_forwards)
```

```{r}
# hybrid of backward and forward, this is not best subset selection according to Elliot
# best subset selection may not be best --> have to consider 2^13 different models
# could use elastic net and lasso
# variable selection methods --> see how they work on the models that are chosen, not really trying to pick the "best model"

anna_best <- step(anna_model, direction = "both")
summary(anna_best)
```
My best subset model is the same as my backwards selected model.


```{r}
dt = sort(sample(nrow(heart_dat), nrow(heart_dat)*.9))
train<-heart_dat[dt,]
test<-heart_dat[-dt,]

anna.best <- regsubsets(output~., data = train, nvmax = 13 )
test.matrix <- model.matrix(output~., data = test)

val.errors=rep(NA,13)
for(i in c(1:13)){
coefi=coef(anna.best,id=i)
pred=test.matrix[,names(coefi)]%*%coefi
val.errors[i]=mean((test$output-pred)^2)
}
which.min(val.errors)
```
the best number of variables changes everytime.


Bestglm, used for logistic regression, regsubset supposedly only does linear models
```{r}
library(bestglm)
heart_dat2 <- heart_dat
names(heart_dat2)[14] <- "y"

best <- bestglm(heart_dat2, family = binomial, IC = "CV")
summary(best$BestModel)
```
Using bestglm model to see how we do with prediction
```{r}
anna_best_final <- glm(output~ sex + cp + thalachh + oldpeak + caa + thall, data = train, family = binomial)
anna_probs <- predict(anna_best_final, test, type = "response")
anna_pred <- rep(0, nrow(test))
anna_pred[anna_probs > 0.5] <- 1

table(anna_pred, test$output)
```
This gives a 71% accuracy


good old glm to stop making my head spin
```{r}
anna_backwards_final <-glm(formula = output ~ sex + cp + trtbps + restecg + thalachh + 
    exng + oldpeak + slp + caa + thall, family = binomial, data = train)
anna_probs <- predict(anna_backwards_final, test, type = "response")
anna_pred <- rep(0, nrow(test))
anna_pred[anna_probs > 0.5] <- 1

table(anna_pred, test$output)
```
This gives 83.8% accuracy

Using LDA for the best model
```{r}
lda_best <- lda(output~ sex + cp + thalachh + oldpeak + caa + thall, data = train)
lda_best_pred <- predict(lda_best, test)

table(lda_best_pred$class, test$output)
```
Does just slightly better than logistic regression


Using LDA for backwards model
```{r}
lda_backwards <- lda(formula = output ~ sex + cp + trtbps + restecg + thalachh + 
    exng + oldpeak + slp + caa + thall, data = train)
lda_backwards_preds <- predict(lda_backwards, test)

table(lda_backwards_preds$class, test$output)
```
does slightly worse than log reg

```{r}
# Performing validation set approach

#training = sample(x = 1:nrow(heart_dat), size = nrow(heart_dat)/2)

training = sample(c(TRUE, FALSE), nrow(heart_dat), rep = TRUE)
testing = (!train)

training_dat <- heart_dat[training,]
testing_dat <- heart_dat[-training,]

anna.best2 <- regsubsets(output~., data = training_dat, nvmax = 13 )
test.matrix2 <- model.matrix(output~., data = testing_dat)

val.errors2=rep(NA,13)
for(i in c(1:13)){
coefi2=coef(anna.best2,id=i)
pred2=test.matrix2[,names(coefi2)]%*%coefi2
val.errors2[i]=mean((testing_dat$output-pred2)^2)
}
which.min(val.errors2)

```


Lasso ***Still need to figure out****

```{r}
#library(glmnet)
x = heart_dat$output
y = model.matrix(output ~ ., data = heart_dat)[,-14]
grid = 10^seq(10,-2,length = 100)

lasso.mod = cv.glmnet(x,y,alpha = 1, lambda = grid, family = "binomial")


```

