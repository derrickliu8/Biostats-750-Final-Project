heart_dat <- read.csv("heart.csv")
head(heart_dat)
heart_dat <- read.csv("heart.csv")
head(heart_dat)
library(leaps)
best_subset_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13)
summary(best_subset_fit)
# Finding the number of predictors in the models selected by best subset selection
# that has the largest R^2
plot(summary(best_subset_fit)$adjr2, xlab = "Number of Variables",
ylab = "Adjusted RSq", type = "l")
which.max(summary(best_subset_fit)$adjr2)
points(10, summary(best_subset_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
forward_step_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13,
method = "forward")
summary(forward_step_fit)
# Finding the number of predictors in the models selected by forward stepwise
# selection that has the largest R^2
plot(summary(forward_step_fit)$adjr2, xlab = "Number of Variables",
ylab = "Adjusted RSq", type = "l")
which.max(summary(forward_step_fit)$adjr2)
points(10, summary(forward_step_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
backward_step_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13,
method = "backward")
summary(backward_step_fit)
# Finding the number of predictors in the models selected by backward stepwise
# selection that has the largest R^2
plot(summary(backward_step_fit)$adjr2, xlab = "Number of Variables",
ylab = "Adjusted RSq", type = "l")
which.max(summary(backward_step_fit)$adjr2)
points(10, summary(backward_step_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
# 10-fold cross validation - code adapted from Lab 4
predict.regsubsets = function (object ,newdata ,id ,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object ,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
k = 10
set.seed(1)
folds = sample(1:k, nrow(heart_dat), replace = TRUE)
cv.errors = matrix(NA, k, 13, dimnames = list(NULL, paste(1:13)))
for(j in 1:k){
best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13)
for(i in 1:13){
pred=predict(best.fit,heart_dat[folds==j,],id=i)
cv.errors[j,i]=mean((heart_dat$output[folds==j]-pred)^2)
}
}
mean.cv.errors = apply(cv.errors, 2, mean)
which.min(mean.cv.errors)
plot(mean.cv.errors, type = "b")
# Finding the best model with 11 predictors using best subset selection
reg.best=regsubsets(output~., data = heart_dat, nvmax=13)
coef(reg.best,11)
# Finding the best model with 11 predictors using forward stepwise selection
reg.best_fwd=regsubsets(output~., data = heart_dat, nvmax=13, method = "forward")
coef(reg.best_fwd,11)
# Finding the best model with 11 predictors using backward stepwise selection
reg.best_backwd=regsubsets(output~., data = heart_dat, nvmax=13, method = "backward")
coef(reg.best_backwd,11)
# QDA on the best model, which has 11 predictors
library(MASS)
qda.fit = qda(output ~ sex+cp+trtbps+chol+restecg+thalachh+exng+oldpeak+slp+caa+thall,
data = heart_dat)
qda.fit
# LDA on the best model, which has 11 predictors
library(MASS)
lda.fit = lda(output ~ sex+cp+trtbps+chol+restecg+thalachh+exng+oldpeak+slp+caa+thall,
data = heart_dat)
lda.fit
heart_logreg <- glm(output~sex+cp+trtbps+chol+restecg+thalachh+exng+oldpeak+slp+caa+thall,
family = "binomial", data = heart_dat)
summary(heart_logreg)
# model with just the statistically significant predictors from above
heart_logreg_red <- glm(output~sex+cp+trtbps+thalachh+exng+oldpeak+caa+thall,
family = "binomial", data = heart_dat)
summary(heart_logreg_red)
heart_dat <- read.csv("heart.csv")
head(heart_dat)
heart_dat <- read.csv("heart.csv")
head(heart_dat)
library(leaps)
best_subset_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13)
summary(best_subset_fit)
# Finding the number of predictors in the models selected by best subset selection
# that has the largest R^2
plot(summary(best_subset_fit)$adjr2, xlab = "Number of Variables",
ylab = "Adjusted RSq", type = "l")
which.max(summary(best_subset_fit)$adjr2)
points(10, summary(best_subset_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
forward_step_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13,
method = "forward")
summary(forward_step_fit)
# Finding the number of predictors in the models selected by forward stepwise
# selection that has the largest R^2
plot(summary(forward_step_fit)$adjr2, xlab = "Number of Variables",
ylab = "Adjusted RSq", type = "l")
which.max(summary(forward_step_fit)$adjr2)
points(10, summary(forward_step_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
backward_step_fit <- regsubsets(output ~ ., data = heart_dat, nvmax = 13,
method = "backward")
summary(backward_step_fit)
# Finding the number of predictors in the models selected by backward stepwise
# selection that has the largest R^2
plot(summary(backward_step_fit)$adjr2, xlab = "Number of Variables",
ylab = "Adjusted RSq", type = "l")
which.max(summary(backward_step_fit)$adjr2)
points(10, summary(backward_step_fit)$adjr2[10], col = "red", cex = 2, pch = 20)
# 10-fold cross validation - code adapted from Lab 4
predict.regsubsets = function (object ,newdata ,id ,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object ,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
k = 10
set.seed(1)
folds = sample(1:k, nrow(heart_dat), replace = TRUE)
cv.errors = matrix(NA, k, 13, dimnames = list(NULL, paste(1:13)))
for(j in 1:k){
best.fit=regsubsets(output~.,data=heart_dat[folds!=j,], nvmax =13)
for(i in 1:13){
pred=predict(best.fit,heart_dat[folds==j,],id=i)
cv.errors[j,i]=mean((heart_dat$output[folds==j]-pred)^2)
}
}
mean.cv.errors = apply(cv.errors, 2, mean)
which.min(mean.cv.errors)
plot(mean.cv.errors, type = "b")
# Finding the best model with 11 predictors using best subset selection
reg.best=regsubsets(output~., data = heart_dat, nvmax=13)
coef(reg.best,11)
# Finding the best model with 11 predictors using forward stepwise selection
reg.best_fwd=regsubsets(output~., data = heart_dat, nvmax=13, method = "forward")
coef(reg.best_fwd,11)
# Finding the best model with 11 predictors using backward stepwise selection
reg.best_backwd=regsubsets(output~., data = heart_dat, nvmax=13, method = "backward")
coef(reg.best_backwd,11)
# have to pick an appropriate training data set criteria
train = (heart_dat$trtbps > 131)
# model with all 11 predictors selected by cross validation
heart_logreg <- glm(output~sex+cp+trtbps+chol+restecg+thalachh+exng+oldpeak+slp+caa+thall,
family = "binomial", data = heart_dat)
summary(heart_logreg)
# model with just the statistically significant predictors from above
heart_logreg_red <- glm(output~sex+cp+trtbps+thalachh+exng+oldpeak+caa+thall,
family = "binomial", data = heart_dat)
summary(heart_logreg_red)
# LDA on the best model, which has 11 predictors
library(MASS)
lda.fit = lda(output ~ sex+cp+trtbps+chol+restecg+thalachh+exng+oldpeak+slp+caa+thall,
data = heart_dat, subset = train)
lda.fit
# QDA on the best model, which has 11 predictors
library(MASS)
qda.fit = qda(output ~ sex+cp+trtbps+chol+restecg+thalachh+exng+oldpeak+slp+caa+thall,
data = heart_dat, subset = train)
qda.fit
library(bestglm)
anna_model <- glm(output~., data = heart_dat, family = binomial)
anna_backwards <- step(anna_model)
summary(anna_backwards)
anna_forwards <- step(anna_model, direction = "forward")
summary(anna_forwards)
anna_best <- step(anna_model, direction = "both")
summary(anna_best)
dt = sort(sample(nrow(heart_dat), nrow(heart_dat)*.9))
train<-heart_dat[dt,]
test<-heart_dat[-dt,]
anna.best <- regsubsets(output~., data = train, nvmax = 13 )
test.matrix <- model.matrix(output~., data = test)
val.errors=rep(NA,13)
for(i in c(1:13)){
coefi=coef(anna.best,id=i)
pred=test.matrix[,names(coefi)]%*%coefi
val.errors[i]=mean((test$output-pred)^2)
}
which.min(val.errors)
best_subset_summ <- summary(best_subset_fit)
which.min(best_subset_summ$bic)
which.min(best_subset_summ$cp)
forward_step_summ <- summary(forward_step_fit)
which.min(forward_step_summ$bic)
which.min(forward_step_summ$cp)
back_step_summ <- summary(backward_step_fit)
which.min(back_step_summ$bic)
which.min(back_step_summ$cp)
stepAIC(best_subset_fit)
which.min(best_subset_summ$aic)
which.min(best_subset_summ$bic)
which.min(best_subset_summ$cp)
heart_dat <- read.csv("heart.csv")
head(heart_dat)
# lasso
library(glmnet)
train=sample(1:nrow(heart_dat), nrow(heart_dat)/2)
test = (-train)
grid=10^seq(10,-2,length=100)
x=model.matrix(output~.,heart_dat)[,-14]
y=heart_dat$output
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out)
bestlam=cv.out$lambda.min # tuning parameter
lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])
mean((lasso.pred-y.test)^2)
y.test=y[test]
mean((lasso.pred-y.test)^2)
# ridge - code adapted from Lab 5
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
ridge.pred=predict(ridge.mod,newx=x[test,])
mean((ridge.pred-y.test)^2)
install.packages("caret")
library(caret)
library(MASS) # for the stepAIC function
library(dplyr) # for the pipeline operator
set.seed(1)
train_samples <- heart_dat %>% createDataPartition(p = 0.9, list = FALSE)
library(caret)
library(MASS) # for the stepAIC function
library(dplyr) # for the pipeline operator
set.seed(1)
train_samples <- heart_dat %>%
createDataPartition(p = 0.9, list = FALSE)
library(caret)
library(MASS) # for the stepAIC function
library(dplyr) # for the pipeline operator
set.seed(1)
full.model <- glm(output ~., data = heart_dat[train], family = binomial) %>%
stepAIC(trace = FALSE)
train
heart_dat[train]
train
heart_dat[train]
heart_dat[train,]
library(caret)
library(MASS) # for the stepAIC function
library(dplyr) # for the pipeline operator
set.seed(1)
full.model <- glm(output ~., data = heart_dat[train,], family = binomial) %>%
stepAIC(trace = FALSE)
#train_samples <- heart_dat %>%
#createDataPartition(p = 0.9, list = FALSE)
#train.data <- heart_dat[train_samples]
#test.data <- heart_dat[-train_samples]
#full.model <- glm(output ~ ., data = train.data, family = binomial) %>%
#stepAIC(trace = FALSE)
full.model
# fitting a model with best subset selection
library(caret)
library(MASS) # for the stepAIC function
library(dplyr) # for the pipeline operator
set.seed(1)
best_subset_logregmodel <- glm(output ~., data = heart_dat[train,], family = binomial) %>%
stepAIC(trace = FALSE)
#train_samples <- heart_dat %>%
#createDataPartition(p = 0.9, list = FALSE)
#train.data <- heart_dat[train_samples]
#test.data <- heart_dat[-train_samples]
#full.model <- glm(output ~ ., data = train.data, family = binomial) %>%
#stepAIC(trace = FALSE)
best_subset_logregmodel
# fitting a model with forward stepwise selection
forward_logregmodel <- glm(output ~., data = heart_dat[train,], family = binomial) %>%
stepAIC(direction = "forward", trace = FALSE)
forward_logregmodel
```{r}
# fitting a model with backward stepwise selection
backward_logregmodel <- glm(output ~., data = heart_dat[train,], family = binomial) %>%
stepAIC(direction = "backward", trace = FALSE)
backward_logregmodel
